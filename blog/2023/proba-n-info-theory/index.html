<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Probability and Information Theory | Duc Minh Quang Nguyen</title> <meta name="author" content="Duc Minh Quang Nguyen"> <meta name="description" content="# A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nminhquang380.github.io/blog/2023/proba-n-info-theory/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Duc Minh Quang </span>Nguyen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Portfolio</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume</a> </li> <li class="nav-item "> <a class="nav-link" href="/bucket_list/">My Bucket List</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Probability and Information Theory</h1> <p class="post-meta">June 26, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/deeplearning"> <i class="fa-solid fa-tag fa-sm"></i> deeplearning</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="1-random-variables">1. Random Variables</h2> <p>A random variable is a variable that can take on different values randomly.</p> <p>Random variables may be discrete or continuous. A discrete random variable is one that has a finite or countably infinite number of states. Note that these states are not necessarily the integers; they can also just be named states that are not considered to have any numerical value. A continuous random variable is associated with a real value.</p> <h2 id="2-probability-distributions">2. Probability Distributions</h2> <p>A probability distribution is a description of <strong>how likely a random variable or set of random variables is to take on each of its possible states</strong>. The way we describe probability distributions depends on whether the variables are discrete or continuous.</p> <h3 id="21-discrete-variables-and-probability-mass-functions">2.1. Discrete Variables and Probability Mass Functions</h3> <p>A probability distribution over discrete variables may be described using a probability mass function (PMF). We typically denote probability mass functions with a capital P. Often we associate each random variable with a different probability mass function and the reader must infer which PMF to use based on the identity of the random variable, rather than on the name of the function; P(x) is usually not the same as P(y).</p> <p>The probability mass function maps from a state of a random variable to the probability of that random variable taking on that state. The probability that x = x is denoted as P(x), with a probability of 1 indicating that x = x is certain and a probability of 0 indicating that x = x is impossible. Sometimes to disambiguate which PMF to use, we write the name of the random variable explicitly: P (x = x).</p> <p>Probability mass functions can act on many variables at the same time. Such a probability distribution over many variables is known as a joint probability distribution. P(x = x, y = y ) denotes the probability that x = x and y = y simultaneously. We may also write P(x, y) for brevity.</p> <h3 id="22-continuous-variables-and-probability-density-functions">2.2. Continuous Variables and Probability Density Functions</h3> <p>When working with continuous random variables, we describe probability distributions using a probability density function (PDF) rather than a probability mass function. To be a probability density function, a function p must satisfy the following properties:</p> <ul> <li>The domain of p must be the set of all possible states of x.</li> <li>∀x ∈ x, p(x) ≥ 0. Note that we do not require p(x) ≤ 1.</li> <li>$\int p(x)dx = 1.$</li> </ul> <p>A probability density function p(x) does not give the probability of a specific state directly; instead the probability of landing inside an infinitesimal region with volume δx is given by p(x)δx.</p> <h2 id="3-marginal-probability">3. Marginal Probability</h2> <p>Sometimes we know the probability distribution over a set of variables and we want to know the probability distribution over just a subset of them. The probability distribution over the subset is known as the marginal probability distribution. For example, suppose we have discrete random variables x and y, and we know P(x, y). We can find P(x) with the sum rule:</p> \[\forall x \in X, P(X= x) = \sum_yP(X= x, Y = y).\] <p>For continuous variables, we need to use integration instead of summation:</p> \[p(x) = \int p(x,y)dy.\] <h2 id="4-conditional-probability">4. Conditional Probability</h2> <p>In many cases, we are interested in the probability of some event, given that some other event has happened. This is called a conditional probability. We denote the conditional probability that y = y given x = x as P(y = y | x = x). This conditional probability can be computed with the formula</p> <p>\(P(Y = y | X= x) = \frac{P(Y=y, X= x)}{P(X=x)}\) The conditional probability is only defined when P(x = x) &gt; 0. We cannot compute the conditional probability conditioned on an event that never happens.</p> <h2 id="5-the-chain-rule-of-conditional-probabilities">5. The Chain Rule of Conditional Probabilities</h2> <p>Any joint probability distribution over many random variables may be decomposed into conditional distributions over only one variable.</p> <p>This observation is known as the chain rule, or product rule, of probability.</p> <p>For example, applying the definition twice, we get</p> \[P(a, b, c) = P(a | b, c)P(b, c)\] \[P(b, c) = P(b | c)P(c)\] \[P(a, b, c) = P(a | b, c)P(b | c)P(c).\] <h2 id="6-independence-and-conditional-independence">6. Independence and Conditional Independence</h2> <p>Two random variables x and y are independent if their probability distribution can be expressed as a product of two factors, one involving only x and one involving only y:</p> <p>∀x ∈ x, y ∈ y, p(x = x, y = y) = p(x = x)p(y = y).</p> <p>Two random variables x and y are conditionally independent given a random variable z if the conditional probability distribution over x and y factorizes in this way for every value of z:</p> <table> <tbody> <tr> <td>∀x ∈ x, y ∈ y, z ∈ z, p(x = x, y = y</td> <td>z = z) = p(x = x</td> <td>z = z)p(y = y</td> <td>z = z).</td> </tr> </tbody> </table> <h2 id="7-expectation-variance-and-covariance">7. Expectation, Variance and Covariance</h2> <p>The <strong>expectation</strong>, or <strong>expected value</strong>, of some function f(x) with respect to a probability distribution P(x) is the average, or mean value, that f takes on when x is drawn from P. For discrete variables this can be computed with a summation: \(E_{x~P}[f(x)] = \sum P(x)f(x)\) while for continuous variables, it is computed with an integral: \(E_{x~P}[f(x)] = \int p(x)f(x)dx\)</p> <p>The <strong>variance</strong> gives a measure of how much the values of a function of a random variable x vary as we sample different values of x from its probability distribution: \(Var(f(x)) = E[(f(x)-E[f(x)])^2]\) When the variance is low, the values of f (x) cluster near their expected value. The square root of the variance is known as the <strong>standard deviation</strong>.</p> <h2 id="8-common-probability-distributions">8. Common Probability Distributions</h2> <h3 id="81-bernoulli-distribution">8.1. Bernoulli Distribution</h3> <p>The Bernoulli distribution is a distribution over a single binary random variable. It is controlled by a single parameter φ ∈ [0, 1], which gives the probability of the random variable being equal to 1.</p> <h3 id="82-multinoulli-distribution">8.2. Multinoulli Distribution</h3> <h3 id="83-gaussian-distribution">8.3. Gaussian Distribution</h3> <p>The most commonly used distribution over real numbers is the normal distribution, also known as the Gaussian distribution</p> <h3 id="84-exponential-and-laplace-distribution">8.4. Exponential and Laplace Distribution</h3> <p>In the context of deep learning, we often want to have a probability distribution with a sharp point at x = 0. To accomplish this, we can use the exponential distribution:</p> <p>p(x; λ) = λ1x≥0 exp (−λx).</p> <h2 id="9-useful-properties-of-common-functions">9. Useful Properties of Common Functions</h2> <p>Certain functions arise often while working with probability distributions, especially the probability distributions used in deep learning models.</p> <p>One of these functions is the logistic sigmoid</p> <h2 id="10-bayes-rule">10. Bayes’ Rule</h2> <p>We often find ourselves in a situation where we know P(y | x) and need to know P (x | y). Fortunately, if we also know P(x), we can compute the desired quantity using Bayes’ rule: \(P(x|y) = \frac{P(x)P(y|x)}{P(y)}\)</p> <h2 id="11-information-theory">11. Information Theory</h2> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/build-ds-project/">Get lost when trying to build a Data Science Project</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/eda/">Exploratory Data Analysis</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/review-machine-learning/">Basic Concepts of Machine Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/error_exception_python/">Error and Exception in Python</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/linear-algebra/">Linear Algebra for AI</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Duc Minh Quang Nguyen. # Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. # Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. # Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>