<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Preprocessing | Duc Minh Quang Nguyen</title> <meta name="author" content="Duc Minh Quang Nguyen"> <meta name="description" content="# A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nminhquang380.github.io/myblog/2023/preprocessing/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Duc Minh Quang </span>Nguyen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Portfolio</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume</a> </li> <li class="nav-item "> <a class="nav-link" href="/bucket_list/">My Bucket List</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Preprocessing</h1> <p class="post-meta">August 1, 2023</p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2023   ·   <i class="fa-solid fa-tag fa-sm"></i> machinelearning   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Data preprocessing is an important step in the data mining process. It refers to the cleaning, transforming, and integrating of data in order to make it ready for analysis. The goal of data preprocessing is to improve the quality of the data and to make it more suitable for the specific data mining task.</p> <h2 id="some-common-steps-in-data-preprocessing-include">Some common steps in data preprocessing include:</h2> <h3 id="data-cleaning">Data Cleaning</h3> <p>This involves indentifying and correcting errors or inconsistenies in the data, such as <strong>missing values, outliers, and duplicates</strong>. Various techniques can be used for data cleaning, such as <strong>imputation</strong>, <strong>removal</strong>, and <strong>transformation</strong>.</p> <h3 id="dat-integration">Dat Integration</h3> <p>This involves combining data from multiple sources to create a <strong>unified dataset</strong>. Data integration can be challenging as it requires handling data with <strong>different formats, structures and semantics</strong>. Techniques such as <strong>record linkage</strong>* and <strong>data fusion</strong>* can be used for data intergration.</p> <h3 id="data-transformation">Data Transformation</h3> <p>This involves converting the data into a <strong>suitable format</strong> for analysis. Common techniques used in data transformation include <strong>normalization</strong>, <strong>standardization</strong>, and <strong>discretization</strong>. Normalization is used to scale the data to a common range, while standardization is used to transform the data to have zero mean and unit variance. Discretization is used to convert continuous data into discrete categories.</p> <h3 id="data-reduction">Data Reduction</h3> <p>This involves <strong>reducing the size</strong> of the dataset while <strong>preserving the important information</strong>. Data reduction can be achieved through techniques such as <strong>feature selection and feature extraction</strong>. Feature selection involves selecting a subset of relevant features from the dataset, while feature extraction involves transforming the data into a lower-dimensional space while preserving the important information.</p> <h3 id="data-discretization">Data Discretization</h3> <p>This involves <strong>dividing continuous data</strong> into <strong>discrete</strong> categories or intervals. Discretization is often used in data mining and machine learning algorithms that require categorical data. Discretization can be achieved through techniques such as equal <strong>width binning</strong>, equal <strong>frequency binning</strong>, and <strong>clustering</strong>.</p> <h3 id="data-normalization">Data Normalization</h3> <p>This involves scaling the data to a common range, such as between 0 and 1 or -1 and 1. Normalization is often used to handle data with different units and scales. Common normalization techniques include min-max normalization, z-score normalization, and decimal scaling.</p> <p><img src="image.png" alt="Alt text"></p> <h2 id="steps-involved-in-data-preprocessing">Steps Involved in Data Preprocessing</h2> <ol> <li> <p><strong>Data Cleaning</strong>: The data can have many irrelevant and missing parts. To handle this part, data cleaning is done. It involves handling of missing data, noisy data etc.</p> <ul> <li> <p><strong>Missing Data</strong>: This situation arises when some data is missing in the data. It can be handled in various ways.</p> <ol> <li> <p><strong>Ignore the tuples</strong>: This approach is suitable only when the dataset we have is quite large and multiple values are missing within a tuple.</p> </li> <li> <p><strong>Fill the Missing values</strong>: There are various ways to do this task. You can choose to fill the missing values manually, by attribute mean or the most probable value.</p> </li> </ol> </li> <li> <p><strong>Noisy Data</strong>: Noisy data is a meaningless data that can’t be interpreted by machines.It can be generated due to faulty data collection, data entry errors etc. It can be handled in following ways :</p> <ol> <li> <p><strong>Binning Method</strong>: This method works on sorted data in order to smooth it. The whole data is divided into segments of equal size and then various methods are performed to complete the task. Each segmented is handled separately. One can replace all data in a segment by its mean or boundary values can be used to complete the task.</p> </li> <li> <p><strong>Regression</strong>: Here data can be made smooth by fitting it to a regression function.The regression used may be linear (having one independent variable) or multiple (having multiple independent variables).</p> </li> <li> <p><strong>Clustering</strong>: This approach groups the similar data in a cluster. The outliers may be undetected or it will fall outside the clusters.</p> </li> </ol> </li> </ul> </li> <li> <strong>Data Transformation</strong> This step is taken in order to transform the data in appropriate forms suitable for mining process. This involves following ways: <ol> <li> <strong>Normalization</strong>: It is done in order to scale the data values in a specified range (-1.0 to 1.0 or 0.0 to 1.0)</li> <li> <strong>Attribute Selection</strong>: New attributes are constructed from the given set of attributes to help the mining process.</li> <li> <strong>Discretization</strong>: This is done to replace the raw values of numeric attribute by interval levels or conceptual levels.</li> <li> <strong>Concept Hierarchy Generation</strong>: Here attributes are converted from lower level to higher level in hierarchy. For example: attribute ‘city’ can be converted to ‘country’.</li> </ol> </li> <li> <p><strong>Data Reduction</strong> Data reduction is a crucial step in the data mining process that involves reducing the size of the dataset while preserving the important information.</p> <ol> <li> <p><strong>Feature Selection</strong>: This involves selecting a subset of relevant features from the dataset. Feature selection is often performed to remove irrelevant or redundant features from the dataset. It can be done using various techniques such as correlation analysis, mutual information, and principal component analysis (PCA).</p> </li> <li> <p><strong>Feature Extraction</strong>: This involves transforming the data into a lower-dimensional space while preserving the important information. Feature extraction is often used when the original features are high-dimensional and complex. It can be done using techniques such as PCA, linear discriminant analysis (LDA), and non-negative matrix factorization (NMF).</p> </li> <li> <p><strong>Sampling</strong>: This involves selecting a subset of data points from the dataset. Sampling is often used to reduce the size of the dataset while preserving the important information. It can be done using techniques such as <strong>random sampling, stratified sampling, and systematic sampling</strong>.</p> </li> <li> <p><strong>Clustering</strong>: This involves <strong>grouping similar data points together</strong> into clusters. Clustering is often used to reduce the size of the dataset by replacing similar data points with a representative centroid. It can be done using techniques such as k-means, hierarchical clustering, and density-based clustering.</p> </li> <li> <p><strong>Compression</strong>: This involves compressing the dataset while preserving the important information. Compression is often used to reduce the size of the dataset for storage and transmission purposes. It can be done using techniques such as wavelet compression, JPEG compression, and gzip compression.</p> </li> </ol> </li> </ol> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/myblog/2023/build-ds-project/">Get lost when trying to build a Data Science Project</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/myblog/2023/review-machine-learning/">Basic Concepts of Machine Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/myblog/2023/eda/">Exploratory Data Analysis</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/myblog/2023/machine-learning-deep-learning/">Difference Between Machine Learning and Deep Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/myblog/2023/intro_pytorch/">Introduction to PyTorch</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Duc Minh Quang Nguyen. # Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. # Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. # Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>